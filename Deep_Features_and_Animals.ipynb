{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#from AI.Features.Segmenting import deep_segment\n",
    "#from AI.Features.SegmentingV2 import deep_segment\n",
    "#from AI.Features.SegmentingV8 import deep_segment\n",
    "\n",
    "#from AI.Features.Segmenting import restore_mask\n",
    "#from AI.Features.SegmentingV8 import restore_mask\n",
    "\n",
    "from skimage import measure\n",
    "import glob\n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from numpy import expand_dims\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot\n",
    "from skimage import feature\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################ Augmentation Function ##################################\n",
    "\n",
    "def augm(lst, nm=5):\n",
    "    # prepare iterator\n",
    "    ls_gen=[]\n",
    "    for arr in lst:\n",
    "        data = arr\n",
    "        # expand dimension to one sample\n",
    "        samples = expand_dims(data, 0)\n",
    "        # create image data augmentation generator\n",
    "        datagen = ImageDataGenerator(zoom_range=[0.5,1.0],\n",
    "                                     brightness_range=[0.8,1],\n",
    "                                     #rotation_range=50,\n",
    "                                     width_shift_range=[0,.1],\n",
    "                                     height_shift_range=[0,.1],\n",
    "                                    #vertical_flip =True,\n",
    "                                    #horizontal_flip=True\n",
    "                                    ) \n",
    "        it = datagen.flow(samples, batch_size=1)\n",
    "        # generate samples and plot\n",
    "\n",
    "        for i in range(nm):\n",
    "            # define subplot\n",
    "            #pyplot.subplot(330 + 1 + i)\n",
    "            # generate batch of images\n",
    "            batch = it.next()\n",
    "            # convert to unsigned integers for viewing\n",
    "            image = batch[0].astype('uint8')\n",
    "            ls_gen.append(image)\n",
    "    return lst+ls_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nuc_and_cyt(segmented):\n",
    "    nuc = (segmented==2).astype('uint8')\n",
    "    cyt = (segmented==1).astype('uint8')\n",
    "    #cyt,nuc=restore_mask(segmented)\n",
    "    return cyt,nuc\n",
    "     \n",
    "def mask_cell(img):\n",
    "    im_mask=deep_segment(img)\n",
    "    #print(im_mask.sum())\n",
    "    #if im_mask.sum()<1000:\n",
    "    #    print(\"No Cell detected\")\n",
    "    #    return img\n",
    "    cyt,nuc= get_nuc_and_cyt(im_mask)\n",
    "    if nuc.sum()!=0:\n",
    "        #reg=measure.regionprops(cyt)\n",
    "        tb=measure.regionprops(nuc)[0]['bbox']\n",
    "    else:\n",
    "        print(\"No cell detected...........\")\n",
    "        tb=(0,0,img.shape[0]-1,img.shape[1]-1)\n",
    "    #img=cv2.blur(img,(3,3))                #++\n",
    "    #img=cv2.medianBlur(img,15)\n",
    "     \n",
    "    im=img.copy()\n",
    "    rows=im_mask.shape[0]\n",
    "    columns=im_mask.shape[1]\n",
    "    for i in range(rows):\n",
    "        for j in range(columns):\n",
    "            if im_mask[i,j]==0:\n",
    "                im[i,j,:]=0\n",
    "    im=im[tb[0]:tb[2],tb[1]:tb[3]]  #to crop it around box\n",
    "    #im=cv2.resize(im,(100,100))\n",
    "    return im\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################### Deep Feature Extractor #################################\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "import time\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pathlib\n",
    "import cv2\n",
    "\n",
    "# Load model into KerasLayer\n",
    "#model_url = \"https://tfhub.dev/google/bit/m-r50x1/1\"\n",
    "#model_url = \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_s/feature_vector/2\" #.99\n",
    "#model_url = \"https://tfhub.dev/google/imagenet/resnet_v2_152/feature_vector/5\"          #97\n",
    "model_url = \".\\imagenet_efficientnet_v2_imagenet21k_s_feature_vector_2\"\n",
    "module = hub.KerasLayer(model_url)\n",
    "\n",
    "def deepfeature(image):\n",
    "    image = np.array(image)\n",
    "    if len(image.shape)==2:\n",
    "        backtorgb = cv2.cvtColor(np.array(image, dtype=np.uint8),cv2.COLOR_GRAY2RGB)\n",
    "        image=backtorgb\n",
    "    image=cv2.resize(image,(384,384))\n",
    "    # reshape into shape [batch_size, height, width, num_channels]\n",
    "    img_reshaped = tf.reshape(image, [1, image.shape[0], image.shape[1], image.shape[2]])\n",
    "    # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "    image = tf.image.convert_image_dtype(img_reshaped, tf.float32)\n",
    "    logits=module(image)\n",
    "    return np.array(logits)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def features(c, f):\n",
    "    if f==1:\n",
    "        return all_together(c) \n",
    "    elif f==2:\n",
    "        return obj.describe(mask_cell(c))\n",
    "    elif f==3:\n",
    "        return LBP_and_extent(c)\n",
    "    elif f==4:\n",
    "        return vggface3(c)\n",
    "    elif f==5:\n",
    "        return SOE_and_extent(c)\n",
    "    elif f==6:\n",
    "        return SOE_LBP_and_extent(c)\n",
    "    elif f==7:\n",
    "        return deepfeature(c)\n",
    "    elif f==8:\n",
    "        return SOE(c)\n",
    "    elif f==9:\n",
    "        return shape_features(c)\n",
    "    elif f==10:\n",
    "        return shapef_and_SOE(c)    \n",
    "    elif f==11:\n",
    "        return shapef_and_SOE_extent(c)    \n",
    "    elif f==12:\n",
    "        return shapef_and_SOE_extent_LBP(c)  \n",
    "    elif f==13:\n",
    "        return shapef_extent(c)  \n",
    "    elif f==14:\n",
    "        return GLCM(mask_cell(c))\n",
    "    elif f==15:\n",
    "        return shapef_GLCM(c)\n",
    "    elif f==16:\n",
    "        return shapef_GLCM_SOE(c)  \n",
    "    elif f==17:\n",
    "        return HOG_im(c)[0]    \n",
    "    elif f==18:\n",
    "        return shapef_GLCM_SOE_HOG(c)\n",
    "    elif f==19:\n",
    "        #PCA\n",
    "        c=cv2.resize(mask_cell(c),(100,100))\n",
    "        return c.reshape(-1)  \n",
    "    elif f==20:\n",
    "        #lda\n",
    "        c=cv2.resize(mask_cell(c),(100,100))\n",
    "        return c.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def alldata(cls,ft):\n",
    "\n",
    "    if cls==2:\n",
    "        lymph_extent = [ features(c, ft) for c in lymph]\n",
    "        neut_extent = [features(c, ft) for c in neut]\n",
    "        x = np.array(lymph_extent + neut_extent)#\n",
    "        if ft==1: x=x.reshape(-1, 1)\n",
    "        y = len(lymph_extent)*[0] + len(neut_extent)*[1]\n",
    "\n",
    "    \n",
    "    elif cls==3:\n",
    "        neut_extent = [features(c, ft) for c in neut]\n",
    "        lymph_extent = [features(c, ft) for c in lymph]\n",
    "        MONO_extent = [ features(c, ft)  for c  in MONO]\n",
    "        x = np.array(lymph_extent + neut_extent+ MONO_extent)#.reshape(-1, 1)\n",
    "        if ft==1: x=x.reshape(-1, 1)\n",
    "        y = len(lymph_extent)*[0] + len(neut_extent)*[1]+len(MONO_extent)*[2]\n",
    "        \n",
    "    elif cls==5:\n",
    "        neut_extent = [features(c, ft)  for c  in neut]\n",
    "        lymph_extent = [features(c, ft)  for c  in lymph]\n",
    "        BASO_extent = [ features(c, ft)  for c  in BASO]\n",
    "        EOSI_extent = [ features(c, ft)  for c in EOSI]\n",
    "        MONO_extent = [ features(c, ft)  for c  in MONO]\n",
    "        x = np.array(lymph_extent + neut_extent+ BASO_extent+ EOSI_extent+ MONO_extent)#.reshape(-1, 1)\n",
    "        if ft==1: x=x.reshape(-1, 1)\n",
    "        y = len(lymph_extent)*[0] + len(neut_extent)*[1]+len(BASO_extent)*[2]+len(EOSI_extent)*[3]+len(MONO_extent)*[4]\n",
    "        \n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ PBC ##################################################\n",
    "\n",
    "lymph = [cv2.imread(f)[:,:,::-1] for f in glob.glob('./samples/PBC/LYMPH/*.jpg')]\n",
    "neut =  [cv2.imread(f)[:,:,::-1] for f in glob.glob('./samples/PBC/NEUT/*.jpg')]\n",
    "BASO =  [cv2.imread(f)[:,:,::-1] for f in glob.glob('./samples/PBC/BASO/*.jpg')]\n",
    "EOSI =  [cv2.imread(f)[:,:,::-1] for f in glob.glob('./samples/PBC/EOSI/*.jpg')]\n",
    "MONO =  [cv2.imread(f)[:,:,::-1] for f in glob.glob('./samples/PBC/MONO/*.jpg')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BCCD Dataset The labels (1- 5) represent neutrophil, lymphocyte, monocyte, eosinophil and basophil, respectively.\n",
    "\n",
    "data1 = [cv2.imread(f)[:,:,::-1] for f in glob.glob('./samples/BCCD/Dataset1/*.bmp')]\n",
    "data2 = [cv2.imread(f)[:,:,::-1] for f in glob.glob('./samples/BCCD/Dataset2/*.bmp')]\n",
    "\n",
    "\n",
    "labels1 = pd.read_csv(\"./samples/BCCD/Class Labels of Dataset 1.csv\") \n",
    "lst1=labels1['class label'].tolist()\n",
    "\n",
    "labels2 = pd.read_csv(\"./samples/BCCD/Class Labels of Dataset 2.csv\") \n",
    "lst2=labels2['class'].tolist()\n",
    "\n",
    "ims=data1#data2+data1\n",
    "lst=lst1# lst2+lst1\n",
    "\n",
    "neut = [ims[i] for i,c in enumerate(lst) if c==1] #+neut\n",
    "lymph = [ims[i] for i,c in enumerate(lst) if c==2] #+lymph\n",
    "MONO =  [ims[i] for i,c in enumerate(lst) if c==3] #+MONO\n",
    "EOSI = [ims[i] for i,c in enumerate(lst) if c==4] #+EOSI \n",
    "BASO =  [ims[i] for i,c in enumerate(lst) if c==5] #+BASO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################### Load Traing Images ###################################################\n",
    "\n",
    "path1='./samples/Animals/goat/*/'      \n",
    "lymph = [cv2.imread(f)[:,:,::-1] for f in glob.glob(path1+'Lymphocyte/*.png') if os.path.getsize(f)>200]\n",
    "neut =  [cv2.imread(f)[:,:,::-1] for f in glob.glob(path1+'Neutrophil/*.png') if os.path.getsize(f)>200]\n",
    "BASO =  [cv2.imread(f)[:,:,::-1] for f in glob.glob(path1+'Basophil/*.png') if os.path.getsize(f)>200]\n",
    "EOSI =  [cv2.imread(f)[:,:,::-1] for f in glob.glob(path1+'Eosinophil/*.png') if os.path.getsize(f)>200]\n",
    "MONO =  [cv2.imread(f)[:,:,::-1] for f in glob.glob(path1+'Monocyte/*.png')if os.path.getsize(f)>200]\n",
    "\n",
    "#GAN\n",
    "#path2='./samples/Monocyte_images/'\n",
    "#MONO_GAN=[cv2.imread(f)[:,:,::-1] for f in glob.glob(path2+'Monocyte/*.jpg')if os.path.getsize(f)>200]\n",
    "#MONO=MONO+MONO_GAN\n",
    "\n",
    "\n",
    "#path3='./samples/Animals/horse/*/'    \n",
    "#MONO_horse =  [cv2.imread(f)[:,:,::-1] for f in glob.glob(path3+'Monocyte/*.png')if os.path.getsize(f)>200]\n",
    "#MONO=MONO+MONO_horse\n",
    "\n",
    " \n",
    "\n",
    "#MONO=augm(MONO, nm=3)\n",
    "#lymph=lymph[2000:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lymph= 40\n",
      "neut= 60\n",
      "MONO= 60\n",
      "BASO= 30\n",
      "EOSI= 30\n",
      "[40, 60, 60, 30, 30]\n",
      "220\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAN5ElEQVR4nO3dfaie913H8fenTUqH7WhDTmJoGo/DUK2DPnCoHYUxl1XiOpb8sUoHq2FUguKkQ2Fk+0PZf/lrTGUoYa0eWTcNezChezJkK0OY3ZKu3VrTmVpiFxqTrLNrp+Jo/frHuYLx5D69r3PO/XB+9v2Cw/X0u3N9+uPup1eu+75OU1VIktpz2bQDSJJWxgKXpEZZ4JLUKAtckhplgUtSo9ZN8mQbN26s2dnZSZ5Skpp3/PjxH1bVzOL9Ey3w2dlZjh07NslTSlLzkvzLoP3eQpGkRlngktQoC1ySGmWBS1KjLHBJapQFLkmN6lXgSa5J8tkkTyc5keQtSTYkOZLkZLe8dtxhJUn/q+8V+B8DX6mqXwRuAk4A+4CjVbUdONptS5ImZGiBJ3kj8FbgAYCq+mlVvQjsAua7YfPA7vFElCQN0udJzDcB54G/SHITcBy4H9hcVWcAqupMkk2DXpxkL7AXYNu2bSMJ/Xoxu++LUznvqf13TeW80zStuYbX53xrNPrcQlkH3Ar8WVXdAvw7y7hdUlUHqmququZmZi55lF+StEJ9Cvw0cLqqHu22P8tCoZ9NsgWgW54bT0RJ0iBDC7yq/hX4QZIbul07gH8EDgN7un17gENjSShJGqjvbyP8PeChJFcAzwLvZ6H8Dya5D3gOuHs8ESVJg/Qq8Kp6HJgbcGjHSNNIknrzSUxJapQFLkmNssAlqVEWuCQ1ygKXpEZZ4JLUKAtckhplgUtSoyxwSWqUBS5JjbLAJalRFrgkNcoCl6RGWeCS1CgLXJIaZYFLUqMscElqlAUuSY2ywCWpURa4JDXKApekRlngktQoC1ySGmWBS1KjLHBJatS6PoOSnAJeBl4FXqmquSQbgL8BZoFTwG9U1b+NJ6YkabHlXIH/alXdXFVz3fY+4GhVbQeOdtuSpAlZzS2UXcB8tz4P7F51GklSb30LvIC/S3I8yd5u3+aqOgPQLTcNemGSvUmOJTl2/vz51SeWJAE974EDd1TV80k2AUeSPN33BFV1ADgAMDc3VyvIKEkaoNcVeFU93y3PAV8AbgPOJtkC0C3PjSukJOlSQws8yc8kufrCOvBrwJPAYWBPN2wPcGhcISVJl+pzC2Uz8IUkF8Z/uqq+kuTbwMEk9wHPAXePL6YkabGhBV5VzwI3Ddj/ArBjHKEkScP5JKYkNcoCl6RGWeCS1CgLXJIaZYFLUqMscElqlAUuSY2ywCWpURa4JDXKApekRlngktQoC1ySGmWBS1KjLHBJapQFLkmNssAlqVEWuCQ1ygKXpEZZ4JLUKAtckhplgUtSoyxwSWqUBS5JjbLAJalRFrgkNcoCl6RG9S7wJJcn+U6Sh7vtDUmOJDnZLa8dX0xJ0mLLuQK/Hzhx0fY+4GhVbQeOdtuSpAnpVeBJtgJ3AZ+8aPcuYL5bnwd2jzSZJOk1res57uPAh4CrL9q3uarOAFTVmSSbBr0wyV5gL8C2bdtWHHR23xdX/NrVOrX/rqmdW5KWMvQKPMm7gHNVdXwlJ6iqA1U1V1VzMzMzK/kjJEkD9LkCvwN4d5J3AlcCb0zyKeBski3d1fcW4Nw4g0qS/q+hV+BV9eGq2lpVs8A9wNeq6n3AYWBPN2wPcGhsKSVJl1jN98D3A3cmOQnc2W1Lkiak74eYAFTVI8Aj3foLwI7RR5Ik9eGTmJLUKAtckhplgUtSoyxwSWqUBS5JjbLAJalRFrgkNcoCl6RGWeCS1CgLXJIaZYFLUqMscElqlAUuSY2ywCWpURa4JDXKApekRlngktQoC1ySGmWBS1KjLHBJapQFLkmNssAlqVEWuCQ1ygKXpEZZ4JLUqKEFnuTKJN9K8kSSp5J8tNu/IcmRJCe75bXjjytJuqDPFfh/AW+vqpuAm4GdSW4H9gFHq2o7cLTbliRNyNACrwU/6TbXdz8F7ALmu/3zwO5xBJQkDbauz6AklwPHgV8APlFVjybZXFVnAKrqTJJNS7x2L7AXYNu2baNJLWnVZvd9cWrnPrX/rqmc9//bP3OvDzGr6tWquhnYCtyW5M19T1BVB6pqrqrmZmZmVhhTkrTYsr6FUlUvAo8AO4GzSbYAdMtzow4nSVpan2+hzCS5plt/A/AO4GngMLCnG7YHODSmjJKkAfrcA98CzHf3wS8DDlbVw0m+CRxMch/wHHD3GHNKkhYZWuBV9V3glgH7XwB2jCOUJGk4n8SUpEZZ4JLUKAtckhplgUtSoyxwSWqUBS5JjbLAJalRFrgkNcoCl6RGWeCS1CgLXJIaZYFLUqMscElqlAUuSY2ywCWpURa4JDXKApekRlngktQoC1ySGmWBS1KjLHBJapQFLkmNssAlqVEWuCQ1ygKXpEZZ4JLUqKEFnuT6JF9PciLJU0nu7/ZvSHIkycluee3440qSLuhzBf4K8AdV9UvA7cDvJrkR2AccrartwNFuW5I0IUMLvKrOVNVj3frLwAngOmAXMN8Nmwd2jymjJGmAZd0DTzIL3AI8CmyuqjOwUPLApiVeszfJsSTHzp8/v8q4kqQLehd4kquAzwEfrKqX+r6uqg5U1VxVzc3MzKwkoyRpgF4FnmQ9C+X9UFV9vtt9NsmW7vgW4Nx4IkqSBunzLZQADwAnqupjFx06DOzp1vcAh0YfT5K0lHU9xtwB3At8L8nj3b6PAPuBg0nuA54D7h5LQknSQEMLvKr+HsgSh3eMNo4kqS+fxJSkRlngktQoC1ySGmWBS1KjLHBJapQFLkmNssAlqVEWuCQ1ygKXpEZZ4JLUKAtckhplgUtSoyxwSWqUBS5JjbLAJalRFrgkNcoCl6RGWeCS1CgLXJIaZYFLUqMscElqlAUuSY2ywCWpURa4JDXKApekRg0t8CQPJjmX5MmL9m1IciTJyW557XhjSpIW63MF/pfAzkX79gFHq2o7cLTbliRN0NACr6pvAD9atHsXMN+tzwO7RxtLkjTMSu+Bb66qMwDdctNSA5PsTXIsybHz58+v8HSSpMXG/iFmVR2oqrmqmpuZmRn36STpdWOlBX42yRaAbnludJEkSX2stMAPA3u69T3AodHEkST11edrhJ8BvgnckOR0kvuA/cCdSU4Cd3bbkqQJWjdsQFW9d4lDO0acRZK0DD6JKUmNssAlqVEWuCQ1ygKXpEZZ4JLUKAtckhplgUtSoyxwSWqUBS5JjbLAJalRFrgkNcoCl6RGWeCS1CgLXJIaZYFLUqMscElqlAUuSY2ywCWpURa4JDXKApekRlngktQoC1ySGmWBS1KjLHBJapQFLkmNssAlqVGrKvAkO5N8P8kzSfaNKpQkabgVF3iSy4FPAL8O3Ai8N8mNowomSXptq7kCvw14pqqeraqfAn8N7BpNLEnSMKmqlb0weQ+ws6p+q9u+F/iVqvrAonF7gb3d5g3A91eYdSPwwxW+dpzMtTzmWh5zLc9azQWry/ZzVTWzeOe6VYTJgH2X/Negqg4AB1ZxnoWTJceqam61f86omWt5zLU85lqetZoLxpNtNbdQTgPXX7S9FXh+dXEkSX2tpsC/DWxP8vNJrgDuAQ6PJpYkaZgV30KpqleSfAD4KnA58GBVPTWyZJda9W2YMTHX8phrecy1PGs1F4wh24o/xJQkTZdPYkpSoyxwSWrUmivwYY/nZ8GfdMe/m+TWNZLrbUl+nOTx7ucPJ5DpwSTnkjy5xPFpzdWwXBOfq+681yf5epITSZ5Kcv+AMROfs565pvH+ujLJt5I80eX66IAx05ivPrmm8h7rzn15ku8keXjAsdHOV1WtmR8WPgz9Z+BNwBXAE8CNi8a8E/gyC99Dvx14dI3kehvw8ITn663ArcCTSxyf+Fz1zDXxuerOuwW4tVu/GvinNfL+6pNrGu+vAFd16+uBR4Hb18B89ck1lfdYd+7fBz496Pyjnq+1dgXe5/H8XcBf1YJ/AK5JsmUN5Jq4qvoG8KPXGDKNueqTayqq6kxVPdatvwycAK5bNGzic9Yz18R1c/CTbnN997P4Ww/TmK8+uaYiyVbgLuCTSwwZ6XyttQK/DvjBRdunufSN3GfMNHIBvKX7a92Xk/zymDP1MY256muqc5VkFriFhau3i011zl4jF0xhzrrbAY8D54AjVbUm5qtHLpjOe+zjwIeA/17i+Ejna60VeJ/H83s9wj9ifc75GAu/r+Am4E+Bvx1zpj6mMVd9THWuklwFfA74YFW9tPjwgJdMZM6G5JrKnFXVq1V1MwtPWt+W5M2Lhkxlvnrkmvh8JXkXcK6qjr/WsAH7Vjxfa63A+zyeP41H+Iees6peuvDXuqr6ErA+ycYx5xpmTf66g2nOVZL1LJTkQ1X1+QFDpjJnw3JN+/1VVS8CjwA7Fx2a6ntsqVxTmq87gHcnOcXCbda3J/nUojEjna+1VuB9Hs8/DPxm92nu7cCPq+rMtHMl+dkk6dZvY2FuXxhzrmGmMVdDTWuuunM+AJyoqo8tMWzic9Yn1zTmLMlMkmu69TcA7wCeXjRsGvM1NNc05quqPlxVW6tqloWO+FpVvW/RsJHO12p+G+HI1RKP5yf57e74nwNfYuGT3GeA/wDev0ZyvQf4nSSvAP8J3FPdx87jkuQzLHzavjHJaeCPWPhAZ2pz1TPXxOeqcwdwL/C97v4pwEeAbRdlm8ac9ck1jTnbAsxn4X/echlwsKoenva/jz1zTes9dolxzpeP0ktSo9baLRRJUk8WuCQ1ygKXpEZZ4JLUKAtckhplgUtSoyxwSWrU/wCnDPfF1Y2LiAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "ln=[len(lymph),len(neut),len(MONO),len(BASO),len(EOSI)]\n",
    "print('lymph=',len(lymph))\n",
    "print('neut=',len(neut))\n",
    "print('MONO=',len(MONO))\n",
    "print('BASO=',len(BASO))\n",
    "print('EOSI=',len(EOSI))\n",
    "\n",
    "print(ln)\n",
    "print(sum(ln))\n",
    "ls5=len(lymph)*[0] + len(neut)*[1]+len(MONO)*[2]+len(BASO)*[3]+len(EOSI)*[4]\n",
    "p=plt.hist(ls5,10)\n",
    "plt.show()\n",
    "\n",
    "y = np.array(ln)\n",
    "mylabels =[\"lymph\",\"neut\",\"MONO\",\"BASO\",\"EOSI\"] \n",
    "plt.figure(figsize=(7, 7))\n",
    "plt.pie(y, labels = mylabels, startangle = 10)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ Extract The Deep Features from Training Set #######################\n",
    "\n",
    "cl=5    # The number of cell types 2,3 or 5\n",
    "fe=7    # The type of the features extractor\n",
    "x,y=alldata(cl,fe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic={0:[1,0,0,0,0],1:[0,1,0,0,0],2:[0,0,1,0,0],3:[0,0,0,1,0],4:[0,0,0,0,1]}\n",
    "y_train=np.array([dic[x]  for x in y_train] )\n",
    "\n",
    "dic={0:[1,0,0,0,0],1:[0,1,0,0,0],2:[0,0,1,0,0],3:[0,0,0,1,0],4:[0,0,0,0,1]}\n",
    "y_test=np.array([dic[x]  for x in y_test] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "12/12 [==============================] - 2s 62ms/step - loss: 1.8680 - accuracy: 0.2203 - val_loss: 1.5950 - val_accuracy: 0.2424\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 1.5701 - accuracy: 0.3583 - val_loss: 1.3435 - val_accuracy: 0.5455\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 1.4429 - accuracy: 0.3037 - val_loss: 1.4113 - val_accuracy: 0.4242\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 1.4617 - accuracy: 0.3437 - val_loss: 1.3448 - val_accuracy: 0.4242\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 1.3157 - accuracy: 0.4375 - val_loss: 1.1096 - val_accuracy: 0.5758\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.2588 - accuracy: 0.4007 - val_loss: 1.1022 - val_accuracy: 0.6667\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 1.3004 - accuracy: 0.4078 - val_loss: 1.0111 - val_accuracy: 0.7879\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.2504 - accuracy: 0.4335 - val_loss: 1.0980 - val_accuracy: 0.6364\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.2077 - accuracy: 0.4950 - val_loss: 0.9776 - val_accuracy: 0.6061\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 1.1728 - accuracy: 0.5024 - val_loss: 0.9351 - val_accuracy: 0.6667\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 1.1340 - accuracy: 0.5196 - val_loss: 0.8946 - val_accuracy: 0.7273\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 1.1013 - accuracy: 0.5621 - val_loss: 0.8995 - val_accuracy: 0.6970\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 1.0480 - accuracy: 0.6027 - val_loss: 0.8650 - val_accuracy: 0.7273\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.0567 - accuracy: 0.5239 - val_loss: 1.1262 - val_accuracy: 0.5152\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.0649 - accuracy: 0.5576 - val_loss: 0.7500 - val_accuracy: 0.8182\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.9540 - accuracy: 0.6096 - val_loss: 0.8703 - val_accuracy: 0.5758\n",
      "Epoch 17/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 1.0129 - accuracy: 0.5858 - val_loss: 0.5760 - val_accuracy: 0.7879\n",
      "Epoch 18/300\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.8377 - accuracy: 0.6300 - val_loss: 0.8000 - val_accuracy: 0.6667\n",
      "Epoch 19/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.8875 - accuracy: 0.6486 - val_loss: 0.6240 - val_accuracy: 0.8182\n",
      "Epoch 20/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.7770 - accuracy: 0.6911 - val_loss: 0.6619 - val_accuracy: 0.7273\n",
      "Epoch 21/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.8672 - accuracy: 0.6760 - val_loss: 0.6328 - val_accuracy: 0.7879\n",
      "Epoch 22/300\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.7541 - accuracy: 0.6924 - val_loss: 0.6452 - val_accuracy: 0.7576\n",
      "Epoch 23/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.7538 - accuracy: 0.7277 - val_loss: 0.6047 - val_accuracy: 0.7879\n",
      "Epoch 24/300\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.8424 - accuracy: 0.6743 - val_loss: 0.6145 - val_accuracy: 0.8182\n",
      "Epoch 25/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.7304 - accuracy: 0.7285 - val_loss: 0.4859 - val_accuracy: 0.7879\n",
      "Epoch 26/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.7079 - accuracy: 0.7347 - val_loss: 0.4057 - val_accuracy: 0.9394\n",
      "Epoch 27/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.6823 - accuracy: 0.7072 - val_loss: 0.5888 - val_accuracy: 0.7879\n",
      "Epoch 28/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.6802 - accuracy: 0.7858 - val_loss: 0.4779 - val_accuracy: 0.9091\n",
      "Epoch 29/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.7027 - accuracy: 0.7458 - val_loss: 0.5079 - val_accuracy: 0.8788\n",
      "Epoch 30/300\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.6516 - accuracy: 0.7477 - val_loss: 0.4374 - val_accuracy: 0.8485\n",
      "Epoch 31/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.7837 - accuracy: 0.6995 - val_loss: 0.3752 - val_accuracy: 0.9091\n",
      "Epoch 32/300\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.5905 - accuracy: 0.7714 - val_loss: 0.3787 - val_accuracy: 0.9091\n",
      "Epoch 33/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.5798 - accuracy: 0.7855 - val_loss: 0.6101 - val_accuracy: 0.7576\n",
      "Epoch 34/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.7177 - accuracy: 0.7009 - val_loss: 0.3752 - val_accuracy: 0.9091\n",
      "Epoch 35/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6562 - accuracy: 0.7566 - val_loss: 0.4546 - val_accuracy: 0.9091\n",
      "Epoch 36/300\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.5406 - accuracy: 0.8079 - val_loss: 0.2856 - val_accuracy: 0.9091\n",
      "Epoch 37/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.5310 - accuracy: 0.8122 - val_loss: 0.3738 - val_accuracy: 0.8788\n",
      "Epoch 38/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4881 - accuracy: 0.8228 - val_loss: 0.3841 - val_accuracy: 0.9091\n",
      "Epoch 39/300\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.5207 - accuracy: 0.8259 - val_loss: 0.3437 - val_accuracy: 0.9394\n",
      "Epoch 40/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.5781 - accuracy: 0.7947 - val_loss: 0.3567 - val_accuracy: 0.9091\n",
      "Epoch 41/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4563 - accuracy: 0.8196 - val_loss: 0.3958 - val_accuracy: 0.9091\n",
      "Epoch 42/300\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4591 - accuracy: 0.8630 - val_loss: 0.2998 - val_accuracy: 0.9091\n",
      "Epoch 43/300\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.5127 - accuracy: 0.7532 - val_loss: 0.2913 - val_accuracy: 0.9091\n",
      "Epoch 44/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.5187 - accuracy: 0.8235 - val_loss: 0.3376 - val_accuracy: 0.9091\n",
      "Epoch 45/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.5278 - accuracy: 0.8080 - val_loss: 0.3771 - val_accuracy: 0.8788\n",
      "Epoch 46/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4085 - accuracy: 0.8718 - val_loss: 0.3621 - val_accuracy: 0.9091\n",
      "Epoch 47/300\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4329 - accuracy: 0.8477 - val_loss: 0.3440 - val_accuracy: 0.8788\n",
      "Epoch 48/300\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.3555 - accuracy: 0.8957 - val_loss: 0.3118 - val_accuracy: 0.8788\n",
      "Epoch 49/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.3734 - accuracy: 0.9098 - val_loss: 0.2901 - val_accuracy: 0.9091\n",
      "Epoch 50/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.5143 - accuracy: 0.8266 - val_loss: 0.2526 - val_accuracy: 0.8788\n",
      "Epoch 51/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.5112 - accuracy: 0.8063 - val_loss: 0.2768 - val_accuracy: 0.8788\n",
      "Epoch 52/300\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.3743 - accuracy: 0.8518 - val_loss: 0.2985 - val_accuracy: 0.9091\n",
      "Epoch 53/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.5366 - accuracy: 0.8041 - val_loss: 0.4124 - val_accuracy: 0.8485\n",
      "Epoch 54/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.3583 - accuracy: 0.8903 - val_loss: 0.2775 - val_accuracy: 0.9394\n",
      "Epoch 55/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4260 - accuracy: 0.8462 - val_loss: 0.3567 - val_accuracy: 0.9091\n",
      "Epoch 56/300\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.4646 - accuracy: 0.8309 - val_loss: 0.2756 - val_accuracy: 0.9091\n",
      "Epoch 57/300\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.3803 - accuracy: 0.8455 - val_loss: 0.2511 - val_accuracy: 0.9394\n",
      "Epoch 58/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 14ms/step - loss: 0.2700 - accuracy: 0.9111 - val_loss: 0.3516 - val_accuracy: 0.8485\n",
      "Epoch 59/300\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.3667 - accuracy: 0.8566 - val_loss: 0.2581 - val_accuracy: 0.9091\n",
      "Epoch 60/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.4550 - accuracy: 0.8198 - val_loss: 0.2911 - val_accuracy: 0.9394\n",
      "Epoch 61/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.3725 - accuracy: 0.8840 - val_loss: 0.2526 - val_accuracy: 0.9394\n",
      "Epoch 62/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.4639 - accuracy: 0.8148 - val_loss: 0.2132 - val_accuracy: 0.9394\n",
      "Epoch 63/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.3990 - accuracy: 0.8513 - val_loss: 0.3673 - val_accuracy: 0.8485\n",
      "Epoch 64/300\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.3420 - accuracy: 0.9021 - val_loss: 0.3269 - val_accuracy: 0.9091\n",
      "Epoch 65/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.3772 - accuracy: 0.8416 - val_loss: 0.2314 - val_accuracy: 0.9091\n",
      "Epoch 66/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.3153 - accuracy: 0.8949 - val_loss: 0.2434 - val_accuracy: 0.9091\n",
      "Epoch 67/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.3916 - accuracy: 0.8700 - val_loss: 0.2720 - val_accuracy: 0.9091\n",
      "Epoch 68/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.3035 - accuracy: 0.8886 - val_loss: 0.1806 - val_accuracy: 0.9697\n",
      "Epoch 69/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.3651 - accuracy: 0.8954 - val_loss: 0.2451 - val_accuracy: 0.9394\n",
      "Epoch 70/300\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.3356 - accuracy: 0.9157 - val_loss: 0.2698 - val_accuracy: 0.9394\n",
      "Epoch 71/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.2984 - accuracy: 0.8840 - val_loss: 0.1869 - val_accuracy: 0.9394\n",
      "Epoch 72/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.3811 - accuracy: 0.8604 - val_loss: 0.2271 - val_accuracy: 0.9091\n",
      "Epoch 73/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.2730 - accuracy: 0.9185 - val_loss: 0.2708 - val_accuracy: 0.8788\n",
      "Epoch 74/300\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.2696 - accuracy: 0.9091 - val_loss: 0.2186 - val_accuracy: 0.9394\n",
      "Epoch 75/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.2878 - accuracy: 0.9156 - val_loss: 0.2425 - val_accuracy: 0.8788\n",
      "Epoch 76/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.2972 - accuracy: 0.8864 - val_loss: 0.2023 - val_accuracy: 0.9394\n",
      "Epoch 77/300\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.2731 - accuracy: 0.8948 - val_loss: 0.2716 - val_accuracy: 0.8788\n",
      "Epoch 78/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4222 - accuracy: 0.8467 - val_loss: 0.2632 - val_accuracy: 0.9091\n",
      "Epoch 79/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.2740 - accuracy: 0.9094 - val_loss: 0.2668 - val_accuracy: 0.9091\n",
      "Epoch 80/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.2917 - accuracy: 0.8691 - val_loss: 0.4181 - val_accuracy: 0.9091\n",
      "Epoch 81/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.2634 - accuracy: 0.9158 - val_loss: 0.3067 - val_accuracy: 0.9394\n",
      "Epoch 82/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.3607 - accuracy: 0.8240 - val_loss: 0.2148 - val_accuracy: 0.9394\n",
      "Epoch 83/300\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.2559 - accuracy: 0.8951 - val_loss: 0.1657 - val_accuracy: 0.9394\n",
      "Epoch 84/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.2387 - accuracy: 0.9104 - val_loss: 0.3172 - val_accuracy: 0.9091\n",
      "Epoch 85/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.2401 - accuracy: 0.9101 - val_loss: 0.1834 - val_accuracy: 0.9697\n",
      "Epoch 86/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.2894 - accuracy: 0.8961 - val_loss: 0.3684 - val_accuracy: 0.8788\n",
      "Epoch 87/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.2979 - accuracy: 0.9276 - val_loss: 0.2014 - val_accuracy: 0.9394\n",
      "Epoch 88/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.2113 - accuracy: 0.9388 - val_loss: 0.2476 - val_accuracy: 0.9394\n",
      "Epoch 89/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.2571 - accuracy: 0.9144 - val_loss: 0.2800 - val_accuracy: 0.9394\n",
      "Epoch 90/300\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.1351 - accuracy: 0.9739 - val_loss: 0.2130 - val_accuracy: 0.9091\n",
      "Epoch 91/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.2652 - accuracy: 0.9297 - val_loss: 0.2440 - val_accuracy: 0.9091\n",
      "Epoch 92/300\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.2743 - accuracy: 0.8947 - val_loss: 0.2064 - val_accuracy: 0.9394\n",
      "Epoch 93/300\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.3166 - accuracy: 0.8777 - val_loss: 0.1889 - val_accuracy: 0.9394\n",
      "Epoch 94/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.2492 - accuracy: 0.9120 - val_loss: 0.4460 - val_accuracy: 0.8788\n",
      "Epoch 95/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.3039 - accuracy: 0.8736 - val_loss: 0.2468 - val_accuracy: 0.9091\n",
      "Epoch 96/300\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.2781 - accuracy: 0.8899 - val_loss: 0.3186 - val_accuracy: 0.9091\n",
      "Epoch 97/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.2335 - accuracy: 0.8998 - val_loss: 0.2187 - val_accuracy: 0.9394\n",
      "Epoch 98/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.3105 - accuracy: 0.8714 - val_loss: 0.2634 - val_accuracy: 0.9091\n",
      "Epoch 99/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.1790 - accuracy: 0.9317 - val_loss: 0.1900 - val_accuracy: 0.9394\n",
      "Epoch 100/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.3943 - accuracy: 0.8381 - val_loss: 0.1938 - val_accuracy: 0.9394\n",
      "Epoch 101/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.2639 - accuracy: 0.9282 - val_loss: 0.2481 - val_accuracy: 0.8788\n",
      "Epoch 102/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.2483 - accuracy: 0.9018 - val_loss: 0.3177 - val_accuracy: 0.8788\n",
      "Epoch 103/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.2508 - accuracy: 0.8906 - val_loss: 0.2766 - val_accuracy: 0.8788\n",
      "Epoch 104/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.2482 - accuracy: 0.9102 - val_loss: 0.2358 - val_accuracy: 0.9091\n",
      "Epoch 105/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.2342 - accuracy: 0.9121 - val_loss: 0.2832 - val_accuracy: 0.8788\n",
      "Epoch 106/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.2249 - accuracy: 0.8975 - val_loss: 0.2193 - val_accuracy: 0.9394\n",
      "Epoch 107/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.2533 - accuracy: 0.8962 - val_loss: 0.2485 - val_accuracy: 0.9091\n",
      "Epoch 108/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.2161 - accuracy: 0.9245 - val_loss: 0.2408 - val_accuracy: 0.8788\n",
      "Epoch 109/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.2529 - accuracy: 0.8851 - val_loss: 0.2186 - val_accuracy: 0.8788\n",
      "Epoch 110/300\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.2156 - accuracy: 0.9114 - val_loss: 0.1969 - val_accuracy: 0.9394\n",
      "Epoch 111/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.2951 - accuracy: 0.8912 - val_loss: 0.2647 - val_accuracy: 0.8788\n",
      "Epoch 112/300\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.1422 - accuracy: 0.9572 - val_loss: 0.2645 - val_accuracy: 0.9091\n",
      "Epoch 113/300\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.2143 - accuracy: 0.9191 - val_loss: 0.2734 - val_accuracy: 0.8788\n",
      "Epoch 114/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.2033 - accuracy: 0.9122 - val_loss: 0.3145 - val_accuracy: 0.9091\n",
      "Epoch 115/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 12ms/step - loss: 0.3038 - accuracy: 0.8986 - val_loss: 0.2859 - val_accuracy: 0.8788\n",
      "Epoch 116/300\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.1700 - accuracy: 0.9285 - val_loss: 0.2172 - val_accuracy: 0.9394\n",
      "Epoch 117/300\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.1828 - accuracy: 0.9440 - val_loss: 0.2963 - val_accuracy: 0.8788\n",
      "Epoch 118/300\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.2339 - accuracy: 0.8972 - val_loss: 0.1951 - val_accuracy: 0.9394\n",
      "Epoch 119/300\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.1478 - accuracy: 0.9586 - val_loss: 0.2714 - val_accuracy: 0.9394\n",
      "Epoch 120/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.2291 - accuracy: 0.9007 - val_loss: 0.3123 - val_accuracy: 0.9091\n",
      "Epoch 121/300\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.2126 - accuracy: 0.9348 - val_loss: 0.1953 - val_accuracy: 0.9394\n",
      "Epoch 122/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.3258 - accuracy: 0.9109 - val_loss: 0.2822 - val_accuracy: 0.8788\n",
      "Epoch 123/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.1856 - accuracy: 0.9340 - val_loss: 0.2199 - val_accuracy: 0.8788\n",
      "Epoch 124/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.2166 - accuracy: 0.9278 - val_loss: 0.2221 - val_accuracy: 0.9091\n",
      "Epoch 125/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.1458 - accuracy: 0.9654 - val_loss: 0.2219 - val_accuracy: 0.9091\n",
      "Epoch 126/300\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.1416 - accuracy: 0.9588 - val_loss: 0.2896 - val_accuracy: 0.8788\n",
      "Epoch 127/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.2034 - accuracy: 0.9217 - val_loss: 0.3815 - val_accuracy: 0.8788\n",
      "Epoch 128/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.2230 - accuracy: 0.9347 - val_loss: 0.2427 - val_accuracy: 0.9091\n",
      "Epoch 129/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.2375 - accuracy: 0.9082 - val_loss: 0.2232 - val_accuracy: 0.9394\n",
      "Epoch 130/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.1816 - accuracy: 0.9216 - val_loss: 0.2350 - val_accuracy: 0.9091\n",
      "Epoch 131/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.2483 - accuracy: 0.8828 - val_loss: 0.3097 - val_accuracy: 0.8788\n",
      "Epoch 132/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.1575 - accuracy: 0.9594 - val_loss: 0.2223 - val_accuracy: 0.9091\n",
      "Epoch 133/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.1816 - accuracy: 0.9129 - val_loss: 0.2877 - val_accuracy: 0.9394\n",
      "Epoch 134/300\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.1514 - accuracy: 0.9363 - val_loss: 0.2230 - val_accuracy: 0.9394\n",
      "Epoch 135/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.1609 - accuracy: 0.9505 - val_loss: 0.3049 - val_accuracy: 0.9091\n",
      "Epoch 136/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.2030 - accuracy: 0.9279 - val_loss: 0.2669 - val_accuracy: 0.8788\n",
      "Epoch 137/300\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.2130 - accuracy: 0.9009 - val_loss: 0.1980 - val_accuracy: 0.9394\n",
      "Epoch 138/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.1764 - accuracy: 0.9418 - val_loss: 0.2323 - val_accuracy: 0.8788\n",
      "Epoch 139/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.2647 - accuracy: 0.9341 - val_loss: 0.2240 - val_accuracy: 0.9091\n",
      "Epoch 140/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.1990 - accuracy: 0.9455 - val_loss: 0.2180 - val_accuracy: 0.9394\n",
      "Epoch 141/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.2190 - accuracy: 0.9238 - val_loss: 0.2345 - val_accuracy: 0.9091\n",
      "Epoch 142/300\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.2095 - accuracy: 0.9060 - val_loss: 0.2550 - val_accuracy: 0.9091\n",
      "Epoch 143/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.1443 - accuracy: 0.9575 - val_loss: 0.2202 - val_accuracy: 0.9091\n",
      "Epoch 144/300\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.1741 - accuracy: 0.9220 - val_loss: 0.1625 - val_accuracy: 0.9394\n",
      "Epoch 145/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.1143 - accuracy: 0.9719 - val_loss: 0.2051 - val_accuracy: 0.9091\n",
      "Epoch 146/300\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.3032 - accuracy: 0.8687 - val_loss: 0.2982 - val_accuracy: 0.9091\n",
      "Epoch 147/300\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.1742 - accuracy: 0.9340 - val_loss: 0.3377 - val_accuracy: 0.8485\n",
      "Epoch 148/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.1739 - accuracy: 0.9488 - val_loss: 0.2387 - val_accuracy: 0.8788\n",
      "Epoch 149/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.1230 - accuracy: 0.9484 - val_loss: 0.2304 - val_accuracy: 0.9091\n",
      "Epoch 150/300\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.1643 - accuracy: 0.9224 - val_loss: 0.3218 - val_accuracy: 0.8788\n",
      "Epoch 151/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.1712 - accuracy: 0.9265 - val_loss: 0.2815 - val_accuracy: 0.9394\n",
      "Epoch 152/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.1387 - accuracy: 0.9600 - val_loss: 0.3567 - val_accuracy: 0.8485\n",
      "Epoch 153/300\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.2271 - accuracy: 0.8967 - val_loss: 0.3648 - val_accuracy: 0.8788\n",
      "Epoch 154/300\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.1737 - accuracy: 0.9278 - val_loss: 0.2564 - val_accuracy: 0.8788\n",
      "Epoch 155/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.1800 - accuracy: 0.9225 - val_loss: 0.2998 - val_accuracy: 0.8788\n",
      "Epoch 156/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.1404 - accuracy: 0.9483 - val_loss: 0.2577 - val_accuracy: 0.9091\n",
      "Epoch 157/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.2386 - accuracy: 0.8993 - val_loss: 0.2488 - val_accuracy: 0.9091\n",
      "Epoch 158/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.1506 - accuracy: 0.9661 - val_loss: 0.1997 - val_accuracy: 0.9091\n",
      "Epoch 159/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.1815 - accuracy: 0.9376 - val_loss: 0.2738 - val_accuracy: 0.9394\n",
      "Epoch 160/300\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.2487 - accuracy: 0.9102 - val_loss: 0.1772 - val_accuracy: 0.9091\n",
      "Epoch 161/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.1564 - accuracy: 0.9362 - val_loss: 0.2751 - val_accuracy: 0.9394\n",
      "Epoch 162/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.1427 - accuracy: 0.9560 - val_loss: 0.3092 - val_accuracy: 0.8788\n",
      "Epoch 163/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.2072 - accuracy: 0.8917 - val_loss: 0.1821 - val_accuracy: 0.9394\n",
      "Epoch 164/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.1999 - accuracy: 0.9070 - val_loss: 0.2854 - val_accuracy: 0.9394\n",
      "Epoch 165/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.1549 - accuracy: 0.9287 - val_loss: 0.2434 - val_accuracy: 0.9394\n",
      "Epoch 166/300\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.1755 - accuracy: 0.9250 - val_loss: 0.2228 - val_accuracy: 0.9394\n",
      "Epoch 167/300\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.1580 - accuracy: 0.9422 - val_loss: 0.2247 - val_accuracy: 0.9091\n",
      "Epoch 168/300\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.1928 - accuracy: 0.9005 - val_loss: 0.2383 - val_accuracy: 0.9091\n",
      "Epoch 169/300\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.1155 - accuracy: 0.9659 - val_loss: 0.2768 - val_accuracy: 0.8788\n",
      "Epoch 170/300\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.2322 - accuracy: 0.8879 - val_loss: 0.2719 - val_accuracy: 0.9091\n",
      "Epoch 171/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.1599 - accuracy: 0.9237 - val_loss: 0.2802 - val_accuracy: 0.9091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/300\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.1196 - accuracy: 0.9597 - val_loss: 0.2822 - val_accuracy: 0.9394\n",
      "Epoch 173/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.2049 - accuracy: 0.8998 - val_loss: 0.2205 - val_accuracy: 0.9394\n",
      "Epoch 174/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.2167 - accuracy: 0.9024 - val_loss: 0.2649 - val_accuracy: 0.9091\n",
      "Epoch 175/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.1971 - accuracy: 0.8928 - val_loss: 0.2577 - val_accuracy: 0.9091\n",
      "Epoch 176/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.1780 - accuracy: 0.9123 - val_loss: 0.2331 - val_accuracy: 0.9091\n",
      "Epoch 177/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.2304 - accuracy: 0.8965 - val_loss: 0.3025 - val_accuracy: 0.9091\n",
      "Epoch 178/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.1710 - accuracy: 0.9341 - val_loss: 0.3243 - val_accuracy: 0.8788\n",
      "Epoch 179/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.1448 - accuracy: 0.9479 - val_loss: 0.2830 - val_accuracy: 0.9394\n",
      "Epoch 180/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.1057 - accuracy: 0.9613 - val_loss: 0.2476 - val_accuracy: 0.9091\n",
      "Epoch 181/300\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.1794 - accuracy: 0.9280 - val_loss: 0.3062 - val_accuracy: 0.8788\n",
      "Epoch 182/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.2181 - accuracy: 0.9036 - val_loss: 0.3673 - val_accuracy: 0.8788\n",
      "Epoch 183/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.2021 - accuracy: 0.9328 - val_loss: 0.2813 - val_accuracy: 0.9091\n",
      "Epoch 184/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.1837 - accuracy: 0.9271 - val_loss: 0.2956 - val_accuracy: 0.9091\n",
      "Epoch 185/300\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0757 - accuracy: 0.9880 - val_loss: 0.2888 - val_accuracy: 0.9091\n",
      "Epoch 186/300\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.1688 - accuracy: 0.9160 - val_loss: 0.2274 - val_accuracy: 0.9091\n",
      "Epoch 187/300\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.1273 - accuracy: 0.9508 - val_loss: 0.2109 - val_accuracy: 0.9394\n",
      "Epoch 188/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.1439 - accuracy: 0.9402 - val_loss: 0.3439 - val_accuracy: 0.9091\n",
      "Epoch 189/300\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.1350 - accuracy: 0.9549 - val_loss: 0.2131 - val_accuracy: 0.9091\n",
      "Epoch 190/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.1565 - accuracy: 0.9415 - val_loss: 0.2116 - val_accuracy: 0.9091\n",
      "Epoch 191/300\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.1821 - accuracy: 0.9334 - val_loss: 0.2313 - val_accuracy: 0.9091\n",
      "Epoch 192/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.1193 - accuracy: 0.9503 - val_loss: 0.3094 - val_accuracy: 0.9091\n",
      "Epoch 193/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.2001 - accuracy: 0.9138 - val_loss: 0.2192 - val_accuracy: 0.9394\n",
      "Epoch 194/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.1348 - accuracy: 0.9390 - val_loss: 0.2414 - val_accuracy: 0.9091\n",
      "Epoch 195/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.1881 - accuracy: 0.9152 - val_loss: 0.3079 - val_accuracy: 0.9091\n",
      "Epoch 196/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.1222 - accuracy: 0.9569 - val_loss: 0.2655 - val_accuracy: 0.9091\n",
      "Epoch 197/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.1227 - accuracy: 0.9645 - val_loss: 0.3090 - val_accuracy: 0.9394\n",
      "Epoch 198/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.1248 - accuracy: 0.9297 - val_loss: 0.1736 - val_accuracy: 0.9394\n",
      "Epoch 199/300\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.1500 - accuracy: 0.9367 - val_loss: 0.1541 - val_accuracy: 0.9394\n",
      "Epoch 200/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0821 - accuracy: 0.9694 - val_loss: 0.3197 - val_accuracy: 0.9091\n",
      "Epoch 201/300\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.1158 - accuracy: 0.9664 - val_loss: 0.2091 - val_accuracy: 0.9394\n",
      "Epoch 202/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.1783 - accuracy: 0.9236 - val_loss: 0.1641 - val_accuracy: 0.9394\n",
      "Epoch 203/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.1448 - accuracy: 0.9530 - val_loss: 0.1686 - val_accuracy: 0.9394\n",
      "Epoch 204/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.1766 - accuracy: 0.9194 - val_loss: 0.2353 - val_accuracy: 0.9091\n",
      "Epoch 205/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.1399 - accuracy: 0.9445 - val_loss: 0.2587 - val_accuracy: 0.9091\n",
      "Epoch 206/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.1377 - accuracy: 0.9359 - val_loss: 0.2256 - val_accuracy: 0.9394\n",
      "Epoch 207/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.1889 - accuracy: 0.9269 - val_loss: 0.3397 - val_accuracy: 0.9091\n",
      "Epoch 208/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.1673 - accuracy: 0.9189 - val_loss: 0.3043 - val_accuracy: 0.9091\n",
      "Epoch 209/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0954 - accuracy: 0.9582 - val_loss: 0.1298 - val_accuracy: 0.9697\n",
      "Epoch 210/300\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.1631 - accuracy: 0.9331 - val_loss: 0.1788 - val_accuracy: 0.9394\n",
      "Epoch 211/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.1047 - accuracy: 0.9577 - val_loss: 0.1520 - val_accuracy: 0.9697\n",
      "Epoch 212/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.2282 - accuracy: 0.8883 - val_loss: 0.1957 - val_accuracy: 0.9394\n",
      "Epoch 213/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.2032 - accuracy: 0.8925 - val_loss: 0.1672 - val_accuracy: 0.9394\n",
      "Epoch 214/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.1671 - accuracy: 0.9391 - val_loss: 0.2039 - val_accuracy: 0.9394\n",
      "Epoch 215/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.1246 - accuracy: 0.9335 - val_loss: 0.2546 - val_accuracy: 0.9091\n",
      "Epoch 216/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.1279 - accuracy: 0.9427 - val_loss: 0.2256 - val_accuracy: 0.9394\n",
      "Epoch 217/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.2189 - accuracy: 0.9196 - val_loss: 0.2361 - val_accuracy: 0.9394\n",
      "Epoch 218/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0928 - accuracy: 0.9657 - val_loss: 0.1896 - val_accuracy: 0.9394\n",
      "Epoch 219/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.1040 - accuracy: 0.9670 - val_loss: 0.2975 - val_accuracy: 0.9091\n",
      "Epoch 220/300\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.1478 - accuracy: 0.9209 - val_loss: 0.2310 - val_accuracy: 0.9394\n",
      "Epoch 221/300\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.1563 - accuracy: 0.9287 - val_loss: 0.2514 - val_accuracy: 0.9394\n",
      "Epoch 222/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.1986 - accuracy: 0.9050 - val_loss: 0.3296 - val_accuracy: 0.8788\n",
      "Epoch 223/300\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.1029 - accuracy: 0.9513 - val_loss: 0.3130 - val_accuracy: 0.8788\n",
      "Epoch 224/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.1060 - accuracy: 0.9487 - val_loss: 0.2394 - val_accuracy: 0.8788\n",
      "Epoch 225/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.1743 - accuracy: 0.9093 - val_loss: 0.2877 - val_accuracy: 0.9091\n",
      "Epoch 226/300\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.1526 - accuracy: 0.9234 - val_loss: 0.3230 - val_accuracy: 0.8788\n",
      "Epoch 227/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.1226 - accuracy: 0.9525 - val_loss: 0.1704 - val_accuracy: 0.9697\n",
      "Epoch 228/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.1428 - accuracy: 0.9361 - val_loss: 0.1911 - val_accuracy: 0.9394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.1745 - accuracy: 0.9130 - val_loss: 0.3545 - val_accuracy: 0.9091\n",
      "Epoch 230/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.1374 - accuracy: 0.9508 - val_loss: 0.2669 - val_accuracy: 0.9394\n",
      "Epoch 231/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.1505 - accuracy: 0.9291 - val_loss: 0.2605 - val_accuracy: 0.9394\n",
      "Epoch 232/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.1880 - accuracy: 0.8885 - val_loss: 0.1504 - val_accuracy: 0.9697\n",
      "Epoch 233/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.1098 - accuracy: 0.9505 - val_loss: 0.1916 - val_accuracy: 0.9394\n",
      "Epoch 234/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.1259 - accuracy: 0.9509 - val_loss: 0.3446 - val_accuracy: 0.9091\n",
      "Epoch 235/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.1156 - accuracy: 0.9367 - val_loss: 0.3849 - val_accuracy: 0.8788\n",
      "Epoch 236/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.1090 - accuracy: 0.9623 - val_loss: 0.3579 - val_accuracy: 0.9091\n",
      "Epoch 237/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.1133 - accuracy: 0.9609 - val_loss: 0.2784 - val_accuracy: 0.9091\n",
      "Epoch 238/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.2275 - accuracy: 0.8979 - val_loss: 0.2336 - val_accuracy: 0.9091\n",
      "Epoch 239/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.1507 - accuracy: 0.9320 - val_loss: 0.1530 - val_accuracy: 0.9394\n",
      "Epoch 240/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.1018 - accuracy: 0.9559 - val_loss: 0.1888 - val_accuracy: 0.9394\n",
      "Epoch 241/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0662 - accuracy: 0.9837 - val_loss: 0.2599 - val_accuracy: 0.9394\n",
      "Epoch 242/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.1697 - accuracy: 0.9398 - val_loss: 0.2538 - val_accuracy: 0.9394\n",
      "Epoch 243/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.1349 - accuracy: 0.9550 - val_loss: 0.2818 - val_accuracy: 0.9394\n",
      "Epoch 244/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.1538 - accuracy: 0.9448 - val_loss: 0.1855 - val_accuracy: 0.9394\n",
      "Epoch 245/300\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.1005 - accuracy: 0.9640 - val_loss: 0.2322 - val_accuracy: 0.9091\n",
      "Epoch 246/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.1639 - accuracy: 0.9353 - val_loss: 0.2347 - val_accuracy: 0.9091\n",
      "Epoch 247/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0790 - accuracy: 0.9694 - val_loss: 0.1936 - val_accuracy: 0.9394\n",
      "Epoch 248/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.1234 - accuracy: 0.9376 - val_loss: 0.2617 - val_accuracy: 0.9091\n",
      "Epoch 249/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.1714 - accuracy: 0.9006 - val_loss: 0.2311 - val_accuracy: 0.9394\n",
      "Epoch 250/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.1468 - accuracy: 0.9411 - val_loss: 0.2360 - val_accuracy: 0.9394\n",
      "Epoch 251/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0940 - accuracy: 0.9730 - val_loss: 0.3180 - val_accuracy: 0.8788\n",
      "Epoch 252/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.1755 - accuracy: 0.9079 - val_loss: 0.3353 - val_accuracy: 0.9091\n",
      "Epoch 253/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.1049 - accuracy: 0.9623 - val_loss: 0.3498 - val_accuracy: 0.9091\n",
      "Epoch 254/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0789 - accuracy: 0.9699 - val_loss: 0.2446 - val_accuracy: 0.9394\n",
      "Epoch 255/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.1346 - accuracy: 0.9245 - val_loss: 0.2604 - val_accuracy: 0.9394\n",
      "Epoch 256/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.1115 - accuracy: 0.9401 - val_loss: 0.2084 - val_accuracy: 0.9394\n",
      "Epoch 257/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.1267 - accuracy: 0.9558 - val_loss: 0.2828 - val_accuracy: 0.9091\n",
      "Epoch 258/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.1782 - accuracy: 0.9058 - val_loss: 0.2241 - val_accuracy: 0.9394\n",
      "Epoch 259/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.1475 - accuracy: 0.9280 - val_loss: 0.2215 - val_accuracy: 0.9091\n",
      "Epoch 260/300\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.1007 - accuracy: 0.9506 - val_loss: 0.2054 - val_accuracy: 0.9091\n",
      "Epoch 261/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0771 - accuracy: 0.9758 - val_loss: 0.2687 - val_accuracy: 0.9091\n",
      "Epoch 262/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.1342 - accuracy: 0.9378 - val_loss: 0.1811 - val_accuracy: 0.9091\n",
      "Epoch 263/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.1998 - accuracy: 0.9095 - val_loss: 0.1789 - val_accuracy: 0.9697\n",
      "Epoch 264/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.1299 - accuracy: 0.9462 - val_loss: 0.1946 - val_accuracy: 0.9394\n",
      "Epoch 265/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.1539 - accuracy: 0.9224 - val_loss: 0.1859 - val_accuracy: 0.9394\n",
      "Epoch 266/300\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.1123 - accuracy: 0.9506 - val_loss: 0.1424 - val_accuracy: 0.9697\n",
      "Epoch 267/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.1143 - accuracy: 0.9578 - val_loss: 0.2024 - val_accuracy: 0.9394\n",
      "Epoch 268/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.1392 - accuracy: 0.9332 - val_loss: 0.1621 - val_accuracy: 0.9394\n",
      "Epoch 269/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.1116 - accuracy: 0.9561 - val_loss: 0.2758 - val_accuracy: 0.9091\n",
      "Epoch 270/300\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.1477 - accuracy: 0.9344 - val_loss: 0.2574 - val_accuracy: 0.9091\n",
      "Epoch 271/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.1276 - accuracy: 0.9480 - val_loss: 0.1585 - val_accuracy: 0.9394\n",
      "Epoch 272/300\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.1155 - accuracy: 0.9562 - val_loss: 0.2644 - val_accuracy: 0.9394\n",
      "Epoch 273/300\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.1567 - accuracy: 0.9330 - val_loss: 0.1442 - val_accuracy: 0.9394\n",
      "Epoch 274/300\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.1482 - accuracy: 0.9212 - val_loss: 0.2092 - val_accuracy: 0.9394\n",
      "Epoch 275/300\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.1531 - accuracy: 0.9490 - val_loss: 0.3397 - val_accuracy: 0.8788\n",
      "Epoch 276/300\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.1485 - accuracy: 0.9420 - val_loss: 0.2297 - val_accuracy: 0.9394\n",
      "Epoch 277/300\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.1515 - accuracy: 0.9452 - val_loss: 0.2673 - val_accuracy: 0.9091\n",
      "Epoch 278/300\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.1585 - accuracy: 0.9438 - val_loss: 0.1986 - val_accuracy: 0.9394\n",
      "Epoch 279/300\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.1409 - accuracy: 0.9493 - val_loss: 0.2677 - val_accuracy: 0.9091\n",
      "Epoch 280/300\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.1507 - accuracy: 0.9331 - val_loss: 0.2256 - val_accuracy: 0.9091\n",
      "Epoch 281/300\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.1190 - accuracy: 0.9642 - val_loss: 0.2543 - val_accuracy: 0.9091\n",
      "Epoch 282/300\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.1460 - accuracy: 0.9411 - val_loss: 0.2146 - val_accuracy: 0.9091\n",
      "Epoch 283/300\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.1926 - accuracy: 0.9132 - val_loss: 0.2369 - val_accuracy: 0.9091\n",
      "Epoch 284/300\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.2256 - accuracy: 0.9121 - val_loss: 0.1991 - val_accuracy: 0.9394\n",
      "Epoch 285/300\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.0731 - accuracy: 0.9781 - val_loss: 0.2850 - val_accuracy: 0.9394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/300\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.1291 - accuracy: 0.9542 - val_loss: 0.3010 - val_accuracy: 0.9091\n",
      "Epoch 287/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.1857 - accuracy: 0.9394 - val_loss: 0.2329 - val_accuracy: 0.9394\n",
      "Epoch 288/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.1204 - accuracy: 0.9509 - val_loss: 0.2155 - val_accuracy: 0.9394\n",
      "Epoch 289/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0948 - accuracy: 0.9825 - val_loss: 0.2554 - val_accuracy: 0.9394\n",
      "Epoch 290/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0842 - accuracy: 0.9711 - val_loss: 0.2136 - val_accuracy: 0.9091\n",
      "Epoch 291/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0946 - accuracy: 0.9764 - val_loss: 0.1824 - val_accuracy: 0.9394\n",
      "Epoch 292/300\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.1293 - accuracy: 0.9447 - val_loss: 0.1890 - val_accuracy: 0.9394\n",
      "Epoch 293/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.1602 - accuracy: 0.9422 - val_loss: 0.1380 - val_accuracy: 0.9394\n",
      "Epoch 294/300\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.1502 - accuracy: 0.9150 - val_loss: 0.2224 - val_accuracy: 0.9394\n",
      "Epoch 295/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.1220 - accuracy: 0.9673 - val_loss: 0.1958 - val_accuracy: 0.9394\n",
      "Epoch 296/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.1289 - accuracy: 0.9406 - val_loss: 0.2552 - val_accuracy: 0.9394\n",
      "Epoch 297/300\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.1134 - accuracy: 0.9455 - val_loss: 0.3479 - val_accuracy: 0.9091\n",
      "Epoch 298/300\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.1827 - accuracy: 0.9262 - val_loss: 0.3325 - val_accuracy: 0.8788\n",
      "Epoch 299/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.1241 - accuracy: 0.9583 - val_loss: 0.2491 - val_accuracy: 0.9091\n",
      "Epoch 300/300\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.1183 - accuracy: 0.9548 - val_loss: 0.1850 - val_accuracy: 0.9394\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e8af38d9a0>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#################################### Deep Front end classification ##################################\n",
    "\n",
    "class_weight = {0: 1,1: 1,2: 1,3:1, 4:1}\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=X_train.shape[1], activation = 'relu'))\n",
    "model.add(Dropout(0.3))\n",
    "#model.add(Dense(50, activation = 'relu'))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation = 'relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(5, activation = 'softmax'))\n",
    "\n",
    "\n",
    "#sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile('sgd',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=300, batch_size=16,  validation_data = (X_test, y_test),class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001E8AF7AE1F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "train_nan=np.isnan(X_train).sum()\n",
    "if train_nan!=0: X_train[np.isnan(X_train)] = 0\n",
    "    \n",
    "test_nan=np.isnan(X_test).sum()\n",
    "if test_nan!=0: X_test[np.isnan(X_test)] = 0\n",
    "\n",
    "predictions=model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9393939393939394\n"
     ]
    }
   ],
   "source": [
    "predictions=predictions*[1,1,1,1,1]\n",
    "print(accuracy_score(y_test.argmax(axis=1), predictions.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       lymph       1.00      0.88      0.93         8\n",
      "        neut       0.83      1.00      0.91        10\n",
      "        BASO       1.00      1.00      1.00         3\n",
      "        EOSI       1.00      0.80      0.89         5\n",
      "        MONO       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           0.94        33\n",
      "   macro avg       0.97      0.93      0.95        33\n",
      "weighted avg       0.95      0.94      0.94        33\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test.argmax(axis=1), predictions.argmax(axis=1) , target_names=[\"lymph\",\"neut\",\"BASO\",\"EOSI\",\"MONO\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7,  1,  0,  0,  0],\n",
       "       [ 0, 10,  0,  0,  0],\n",
       "       [ 0,  0,  3,  0,  0],\n",
       "       [ 0,  1,  0,  4,  0],\n",
       "       [ 0,  0,  0,  0,  7]], dtype=int64)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test.argmax(axis=1), predictions.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "############################## plot the confusion matrix ##########################################\n",
    "import itertools\n",
    "\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.cool):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "    # Predict the values from the validation dataset\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "confusion_mtx = confusion_matrix(y_test.argmax(axis=1), Y_pred.argmax(axis=1)) \n",
    "# plot the confusion matrix\n",
    "plot_confusion_matrix(confusion_mtx, classes = [\"lymph\",\"neut\",\"BASO\",\"EOSI\",\"MONO\"])#range(5)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
